{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bahdanau 注意力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个带有Bahdanau注意力的循环神经网络编码器-解码器模型\n",
    "\n",
    "![seq2seq-attention-details.svg](https://zh-v2.d2l.ai/_images/seq2seq-attention-details.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "from torch import nn\n",
    "import d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(d2l.Decoder):\n",
    "  '''带有注意力机制解码器的基本接口'''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  @property\n",
    "  def attention_weights(self):\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttentionDecoder(AttentionDecoder):\n",
    "  def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0):\n",
    "    super().__init__()\n",
    "    self.attention = d2l.AdditiveAttention(\n",
    "      num_hiddens, num_hiddens, num_hiddens, dropout\n",
    "    )\n",
    "    self.embedding = nn.Embedding(\n",
    "      vocab_size, embed_size\n",
    "    )\n",
    "    self.rnn = nn.GRU(\n",
    "      embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout\n",
    "    )\n",
    "    self.dense = nn.Linear(\n",
    "      num_hiddens, vocab_size\n",
    "    )\n",
    "  \n",
    "  def init_state(self, enc_outputs, enc_valid_lens):\n",
    "    # outputs的形状为(batch_size，num_steps，num_hiddens).\n",
    "    # hidden_state的形状为(num_layers，batch_size，num_hiddens)\n",
    "    outputs, hidden_state = enc_outputs\n",
    "    return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens)\n",
    "  \n",
    "  def forward(self, X, state):\n",
    "    # enc_outputs的形状为(batch_size,num_steps,num_hiddens).\n",
    "    # hidden_state的形状为(num_layers,batch_size,\n",
    "    # num_hiddens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
